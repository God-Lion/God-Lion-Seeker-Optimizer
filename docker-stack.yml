version: '3.8'

services:
  # ==================== DATABASE LAYER ====================
  postgres:
    image: postgres:15-alpine
    networks:
      - db-backend-network
      - scraper-swarm-network
    secrets:
      - db_username
      - db_password
      - db_name
    environment:
      POSTGRES_USER_FILE: /run/secrets/db_username
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
      POSTGRES_DB_FILE: /run/secrets/db_name
    volumes:
      - type: bind
        source: /mnt/swarm-storage/postgres
        target: /var/lib/postgresql/data
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.role == database
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U scraper_user -d godlionseeker"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==================== CACHE LAYER ====================
  redis:
    image: redis:7-alpine
    networks:
      - scraper-swarm-network
    volumes:
      - type: bind
        source: /mnt/swarm-storage/redis
        target: /data
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.role == cache
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==================== API LAYER (AUTO-SCALING) ====================
  api:
    image: ${REGISTRY_URL}/godlionseeker-api:latest
    networks:
      - scraper-swarm-network
      - db-backend-network
    secrets:
      - db_username
      - db_password
      - db_name
      - jwt_secret_key
    environment:
      DATABASE_URL: postgresql+asyncpg://scraper_user:scraper_password@postgres:5432/godlionseeker
      REDIS_URL: redis://redis:6379/0
      APP_NAME: God Lion Seeker Optimizer
      ENVIRONMENT: production
      DEBUG: "false"
      API_HOST: 0.0.0.0
      API_PORT: 8000
    volumes:
      - type: bind
        source: /mnt/swarm-storage/logs
        target: /app/logs
      - type: bind
        source: /mnt/swarm-storage/data
        target: /app/data
    deploy:
      mode: replicated
      replicas: 3
      placement:
        constraints:
          - node.labels.role == api
        preferences:
          - spread: node.id
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
        monitor: 30s
        max_failure_ratio: 0.3
        order: start-first
      rollback_config:
        parallelism: 1
        delay: 5s
        failure_action: pause
        monitor: 30s
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
      # Auto-scaling labels for external tools
      labels:
        com.docker.swarm.service.name: "api"
        prometheus.scrape: "true"
        prometheus.port: "8000"
        prometheus.path: "/metrics"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ==================== CLIENT LAYER ====================
  client:
    image: ${REGISTRY_URL}/godlionseeker-client:latest
    networks:
      - scraper-swarm-network
    deploy:
      mode: replicated
      replicas: 2
      placement:
        preferences:
          - spread: node.id
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==================== LOAD BALANCER ====================
  nginx:
    image: nginx:alpine
    networks:
      - scraper-swarm-network
    configs:
      - source: nginx_config
        target: /etc/nginx/nginx.conf
      - source: nginx_default_conf
        target: /etc/nginx/conf.d/default.conf
    secrets:
      - source: nginx_ssl_cert
        target: /etc/nginx/nginx-selfsigned.crt
      - source: nginx_ssl_key
        target: /etc/nginx/nginx-selfsigned.key
    ports:
      - target: 80
        published: 80
        mode: host
      - target: 443
        published: 443
        mode: host
    volumes:
      - type: bind
        source: /mnt/swarm-storage/logs/nginx
        target: /var/log/nginx
    deploy:
      mode: global
      placement:
        constraints:
          - node.role == manager
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ==================== MONITORING LAYER ====================
  prometheus:
    image: prom/prometheus:latest
    networks:
      - scraper-swarm-network
    configs:
      - source: prometheus_config
        target: /etc/prometheus/prometheus.yml
    volumes:
      - type: bind
        source: /mnt/swarm-storage/prometheus
        target: /prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: on-failure
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  grafana:
    image: grafana/grafana:latest
    networks:
      - scraper-swarm-network
    secrets:
      - grafana_admin_password
    environment:
      GF_SECURITY_ADMIN_PASSWORD__FILE: /run/secrets/grafana_admin_password
      GF_USERS_ALLOW_SIGN_UP: "false"
    volumes:
      - type: bind
        source: /mnt/swarm-storage/grafana
        target: /var/lib/grafana
    ports:
      - "127.0.0.1:3000:3000"
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: on-failure
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

# ==================== NETWORKS ====================
networks:
  scraper-swarm-network:
    external: true
  db-backend-network:
    external: true

# ==================== SECRETS ====================
secrets:
  db_username:
    external: true
  db_password:
    external: true
  db_name:
    external: true
  jwt_secret_key:
    external: true
  grafana_admin_password:
    external: true
  nginx_ssl_cert:
    external: true
  nginx_ssl_key:
    external: true

# ==================== CONFIGS ====================
configs:
  nginx_config:
    external: true
  nginx_default_conf:
    external: true
  prometheus_config:
    external: true
